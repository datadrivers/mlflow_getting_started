{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "descending-coffee",
   "metadata": {},
   "source": [
    "# Serve a pyfunc model via pyspark\n",
    "\n",
    "This notebook shows how a registred model can be served via pyspark for parallelization purposes. \n",
    "\n",
    "Note that the local simulation here is for the purpose of code and concept representation. Parallelization only makes sense where several processing units can be controlled in one cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import StorageLevel\n",
    "import mlflow\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\")\n",
    "from config import mlflow_server_uri\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import StructType, StringType, StructField, ArrayType, LongType, DoubleType, IntegerType, \\\n",
    "    DecimalType, FloatType, BooleanType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_server_uri)\n",
    "mlflow.set_registry_uri(mlflow_server_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-contrary",
   "metadata": {},
   "source": [
    "## Init pyspark and load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-village",
   "metadata": {},
   "source": [
    "Please note the following pitfalls regarding Spark in a local setup:\n",
    "    \n",
    "* Make sure that the PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON variables are set correctly: The driver and worker should point to the venv.\n",
    "* In this repo, utils und config are used as modules. They need to be copied to the venv, since the driver and worker search here for packages. This must also be taken into account when working with a cluster in the cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_path = os.path.abspath(\"../venv/bin/python\")\n",
    "\n",
    "# Set spark environments\n",
    "os.environ['PYSPARK_PYTHON'] = python_path\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = python_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp -r ../utils ../venv/lib/python3.8/site-packages/utils\n",
    "! cp -r ../config ../venv/lib/python3.8/site-packages/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session: SparkSession = SparkSession.builder.master(\"local\").appName(\"HelloWorld\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA: StructType = StructType([\n",
    "        StructField(\"host_total_listings_count\", FloatType(), True),\n",
    "        StructField(\"neighbourhood_cleansed\", IntegerType(), True),\n",
    "        StructField(\"zipcode\", IntegerType(), True),\n",
    "        StructField(\"latitude\", FloatType(), True),\n",
    "        StructField(\"longitude\", FloatType(), True),\n",
    "        StructField(\"property_type\", IntegerType(), True),\n",
    "        StructField(\"room_type\", IntegerType(), True),\n",
    "        StructField(\"accommodates\", FloatType(), True),\n",
    "        StructField(\"bathrooms\", FloatType(), True),\n",
    "        StructField(\"bedrooms\", FloatType(), True),\n",
    "        StructField(\"beds\", FloatType(), True),\n",
    "        StructField(\"bed_type\", IntegerType(), True),\n",
    "        StructField(\"minimum_nights\", FloatType(), True),\n",
    "        StructField(\"number_of_reviews\", FloatType(), True),\n",
    "        StructField(\"review_scores_rating\", FloatType(), True),\n",
    "        StructField(\"review_scores_accuracy\", FloatType(), True),\n",
    "        StructField(\"review_scores_cleanliness\", FloatType(), True),\n",
    "        StructField(\"review_scores_checkin\", FloatType(), True),\n",
    "        StructField(\"review_scores_communication\", FloatType(), True),\n",
    "        StructField(\"review_scores_location\", FloatType(), True),\n",
    "        StructField(\"review_scores_value\", FloatType(), True),\n",
    "        StructField(\"price\", FloatType(), True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark_session.read.csv(\"../data/airbnb-cleaned-mlflow.csv\", header=True, schema=SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-wisconsin",
   "metadata": {},
   "source": [
    "## Load the price regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"My_airbnb_model\"\n",
    "stage = \"Production\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.spark_udf(model_uri = f\"models:/{model_name}/{stage}\",\n",
    "                                       spark=spark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-adolescent",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"prediction\", loaded_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-nation",
   "metadata": {},
   "source": [
    "## Stop spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-companion",
   "metadata": {},
   "source": [
    "# Learnings\n",
    "\n",
    "\n",
    "* Always stick to the latest version of mlflow. When it comes to the model registry and deployment purposes it becomes visible that this tool is constantly being worked on.\n",
    "* When building a custom pyfunc model, we would recommended to define a signature for the model to gain security here.\n",
    "* However, the wrapper of the PyFunc Objekt which enforces the correct data types for the internal is extremely sensitive (!). Schema compatibility between training and prediction datasets should be ensured up front.\n",
    "* In the meantime, however, any error messages that may occur are already much more verbose than in earlier versions, that closes the circle to the first point :-) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-microwave",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "https://mlflow.org/docs/latest/models.html#export-a-python-function-model-as-an-apache-spark-udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-equity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_venv",
   "language": "python",
   "name": "mlflow_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
